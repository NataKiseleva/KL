{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwwq68F5V71m",
        "outputId": "2c906749-f0b4-4851-d47f-dc888bf61489"
      },
      "source": [
        "!pip install tokenizers matplotlib sklearn"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Z944-R1MeANU",
        "outputId": "d70776db-2e4d-4ba3-9725-756f9d7a5d74"
      },
      "source": [
        "!pip install torch==1.8.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/74/6fc9dee50f7c93d6b7d9644554bdc9692f3023fa5d1de779666e6bf8ae76/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "Successfully installed torch-1.8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBMi1iZIW3x8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWY7Q2hoW-kC"
      },
      "source": [
        "en_sents = open('opus.en-ru-train.en.txt').read().splitlines()\n",
        "ru_sents = open('opus.en-ru-train.ru.txt').read().replace('\\xa0', ' ').splitlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UECGYtOXCHV",
        "outputId": "4c404a2c-9b65-4877-f6c5-f588a0089920"
      },
      "source": [
        "en_sents[-1], ru_sents[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('So what are you thinking?', 'Ну и что ты думаешь?')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTdnIGbyXFMD"
      },
      "source": [
        "tokenizer_en = Tokenizer(BPE())\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "trainer_en = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
        "tokenizer_en.train(files=[\"opus.en-ru-train.en.txt\"], trainer=trainer_en)\n",
        "\n",
        "tokenizer_ru = Tokenizer(BPE())\n",
        "tokenizer_ru.pre_tokenizer = Whitespace()\n",
        "trainer_ru = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
        "tokenizer_ru.train(files=[\"opus.en-ru-train.ru.txt\"], trainer=trainer_ru)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX0dyqPNXJLr"
      },
      "source": [
        "# tokenizer_en.save('tokenizer_en')\n",
        "# tokenizer_ru.save('tokenizer_ru')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuGDksinXMsR"
      },
      "source": [
        "text, tokenizer, max_len):\n",
        "    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids[:max_len] + [tokenizer.token_to_id('[SEP]')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MIKBKxHftRE"
      },
      "source": [
        "def encode(text, tokenizer, max_len):\n",
        "    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids[:max_len] + [tokenizer.token_to_id('[SEP]')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrMzipj_XQPT",
        "outputId": "4c7623d6-1a65-4619-fdb2-c760812681cc"
      },
      "source": [
        "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
        "PAD_IDX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-HyqdfXS66"
      },
      "source": [
        "max_len_en, max_len_ru = 30, 35"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVEFNoZWXWDz"
      },
      "source": [
        "X_en = [encode(t, tokenizer_en, max_len_en) for t in en_sents]\n",
        "X_ru = [encode(t, tokenizer_ru, max_len_ru) for t in ru_sents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXk5QoinXZKm"
      },
      "source": [
        "X_en.shape, X_ru.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnBmUcQdXbxw"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, texts_en, texts_ru):\n",
        "        self.texts_en = [torch.LongTensor(sent) for sent in texts_en]\n",
        "        self.texts_en = torch.nn.utils.rnn.pad_sequence(self.texts_en, padding_value=PAD_IDX)\n",
        "        \n",
        "        self.texts_ru = [torch.LongTensor(sent) for sent in texts_ru]\n",
        "        self.texts_ru = torch.nn.utils.rnn.pad_sequence(self.texts_ru, padding_value=PAD_IDX)\n",
        "\n",
        "        self.length = len(texts_en)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        ids_en = self.texts_en[:, index]\n",
        "        ids_ru = self.texts_ru[:, index]\n",
        "\n",
        "        return ids_en, ids_ru"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEI1lFr1Xg1U"
      },
      "source": [
        "X_en_train, X_en_valid, X_ru_train, X_ru_valid = train_test_split(X_en, X_ru, test_size=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJStpPO6Xkkg"
      },
      "source": [
        "training_set = Dataset(X_en_train, X_ru_train)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=200, shuffle=True,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adKIa0-JXpJ_"
      },
      "source": [
        "valid_set = Dataset(X_en_valid, X_ru_valid)\n",
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=200, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6voc7h9Xsnk"
      },
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 150):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size, \n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "#         print('pos inp')\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "#         print('pos dec')\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "#         print('pos out')\n",
        "        x = self.generator(outs)\n",
        "#         print('gen')\n",
        "        return x\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)\n",
        "# During training, we need a subsequent word mask that will prevent model to look into the future words when making predictions. We will also need masks to hide source and target padding tokens. Below, let’s define a function that will take care of both.\n",
        "\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    \n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNyQ_aF9XzjX"
      },
      "source": [
        "from time import time\n",
        "def train(model, iterator, optimizer, criterion, print_every=500):\n",
        "    \n",
        "    epoch_loss = []\n",
        "    ac = []\n",
        "    \n",
        "    model.train()  \n",
        "\n",
        "    for i, (texts_en, texts_ru) in enumerate(iterator):\n",
        "        texts_en = texts_en.T.to(DEVICE) # чтобы батч был в конце\n",
        "        texts_ru = texts_ru.T.to(DEVICE) # чтобы батч был в конце\n",
        "        \n",
        "        # помимо текста в модель еще нужно передать целевую последовательность\n",
        "        # но не полную а без 1 последнего элемента\n",
        "        # а на выходе ожидаем, что модель сгенерирует этот недостающий элемент\n",
        "        texts_ru_input = texts_ru[:-1, :]\n",
        "        \n",
        "        \n",
        "        # в трансформерах нет циклов как в лстм \n",
        "        # каждый элемент связан с каждым через аттеншен\n",
        "        # чтобы имитировать последовательную обработку\n",
        "        # и чтобы не считать аттеншн с паддингом \n",
        "        # в трансформерах нужно считать много масок\n",
        "        # подробнее про это по ссылкам выше\n",
        "        (texts_en_mask, texts_ru_mask, \n",
        "        texts_en_padding_mask, texts_ru_padding_mask) = create_mask(texts_en, texts_ru_input)\n",
        "        logits = model(texts_en, texts_ru_input, texts_en_mask, texts_ru_mask,\n",
        "                       texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # сравниваем выход из модели с целевой последовательностью уже с этим последним элементом\n",
        "        texts_ru_out = texts_ru[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), texts_ru_out.reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss.append(loss.item())\n",
        "        \n",
        "        if not (i+1) % print_every:\n",
        "            print(f'Loss: {np.mean(epoch_loss)};')\n",
        "        \n",
        "    return np.mean(epoch_loss)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = []\n",
        "    epoch_f1 = []\n",
        "    \n",
        "    model.eval()  \n",
        "    with torch.no_grad():\n",
        "        for i, (texts_en, texts_ru) in enumerate(iterator):\n",
        "            texts_en = texts_en.T.to(DEVICE)\n",
        "            texts_ru = texts_ru.T.to(DEVICE)\n",
        "\n",
        "            texts_ru_input = texts_ru[:-1, :]\n",
        "\n",
        "            (texts_en_mask, texts_ru_mask, \n",
        "            texts_en_padding_mask, texts_ru_padding_mask) = create_mask(texts_en, texts_ru_input)\n",
        "\n",
        "            logits = model(texts_en, texts_ru_input, texts_en_mask, texts_ru_mask,\n",
        "                           texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
        "\n",
        "            \n",
        "            texts_ru_out = texts_ru[1:, :]\n",
        "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), texts_ru_out.reshape(-1))\n",
        "            epoch_loss.append(loss.item())\n",
        "            \n",
        "    return np.mean(epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-nm-I9oX8Qn"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "EN_VOCAB_SIZE = tokenizer_en.get_vocab_size()\n",
        "RU_VOCAB_SIZE = tokenizer_ru.get_vocab_size()\n",
        "\n",
        "EMB_SIZE = 256\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "NUM_ENCODER_LAYERS = 2\n",
        "NUM_DECODER_LAYERS = 2\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, EN_VOCAB_SIZE, RU_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzVyuolAYAhb"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iAJ_Z8mYFBt"
      },
      "source": [
        "transformer = torch.load('model').to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyAznLp4isN0",
        "outputId": "cbd06f72-3203-41a7-af6b-23a490ad72e8"
      },
      "source": [
        "!pip install spacy==3.0.5\n",
        "!python3 -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "model_en = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy==3.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/70/a0b8bd0cb54d8739ba4d6fb3458785c3b9b812b7fbe93b0f10beb1a53ada/spacy-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 242kB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
            "Collecting srsly<3.0.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (4.5.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (3.7.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (20.9)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/a5/a727792d000b2a7bfcccbad03b292cd4c2d567d271fc3cab91250c2461e8/spacy_legacy-3.0.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (2.23.0)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 180kB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/82/b0f35c2013da8a372bb2948dc3fa0b840f71a8ed02bfe0b7809ae13271bc/thinc-8.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618kB)\n",
            "\u001b[K     |████████████████████████████████| 624kB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (0.8.2)\n",
            "Collecting pathy>=0.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (57.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (2.11.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.5) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.1->spacy==3.0.5) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.0.5) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.5) (2021.5.30)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3.0.5) (7.1.2)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 59.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.0.5) (2.0.1)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107107 sha256=690549662faf213e78b0adc4385ec88e8ea2af132b1ec0aa504221aa9c744b97\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built smart-open\n",
            "Installing collected packages: catalogue, srsly, spacy-legacy, typer, pydantic, thinc, smart-open, pathy, spacy\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: smart-open 5.1.0\n",
            "    Uninstalling smart-open-5.1.0:\n",
            "      Successfully uninstalled smart-open-5.1.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.5 spacy-legacy-3.0.6 srsly-2.4.1 thinc-8.0.5 typer-0.3.2\n",
            "2021-06-20 08:25:27.155088: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting en-core-web-sm==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7MB 17.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (57.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.5.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCf6pA_-hRbF"
      },
      "source": [
        "def translate(text):\n",
        "\n",
        "    doc = model_en(text)\n",
        "    Input_ids = []\n",
        "    Output_ids = []\n",
        "\n",
        "    for sent in doc.sents:\n",
        "          sent = str(sent)\n",
        "          input_ids = [tokenizer_en.token_to_id('[CLS]')] + tokenizer_en.encode(sent).ids[:max_len_en] + [tokenizer_en.token_to_id('[SEP]')]    \n",
        "          Input_ids.append(input_ids)\n",
        "          Output_ids.append([tokenizer_ru.token_to_id('[CLS]')])\n",
        "\n",
        "    input_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(i) for i in Input_ids]).to(DEVICE)\n",
        "    output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(i) for i in Output_ids]).to(DEVICE)\n",
        "   \n",
        "    (texts_en_mask, texts_ru_mask, \n",
        "    texts_en_padding_mask, texts_ru_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
        "    logits = transformer(input_ids_pad, output_ids_pad, texts_en_mask, texts_ru_mask,\n",
        "                   texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
        "    pred_list =[]\n",
        "    for i, logit in enumerate(torch.flatten(logits.argmax(2))):\n",
        "      #print(logit.item())\n",
        "      pred = logit.item()\n",
        "      pred_list.append(pred)\n",
        "\n",
        "    while any([pred[-1] not in [tokenizer_ru.token_to_id('[SEP]'), tokenizer_ru.token_to_id('[PAD]')] for pred in Output_ids]):\n",
        "        for i in range(len(pred_list)):\n",
        "          if Output_ids[i][-1] in [tokenizer_ru.token_to_id('[SEP]'), tokenizer_ru.token_to_id('[PAD]')]:              \n",
        "              continue\n",
        "          else:\n",
        "              Output_ids[i].append(pred_list[i])\n",
        "\n",
        "        output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(i) for i in Output_ids]).to(DEVICE)\n",
        "\n",
        "        (texts_en_mask, texts_ru_mask, \n",
        "        texts_en_padding_mask, texts_ru_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
        "        logits = transformer(input_ids_pad, output_ids_pad, texts_en_mask, texts_ru_mask,\n",
        "                      texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
        "        pred_list =[]\n",
        "        for i, logit in enumerate(torch.flatten(logits.argmax(2)[-1])):\n",
        "          #print(logit.item())\n",
        "          pred = logit.item()\n",
        "          pred_list.append(pred)\n",
        "        \n",
        "    translate_out = []\n",
        "    for i in Output_ids:\n",
        "      translate_out.append(' '.join([tokenizer_ru.id_to_token(x).replace('##', '') for x in i[1:-1]]))\n",
        "\n",
        "    return translate_out"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUNe0GYrjP3P"
      },
      "source": [
        "text = open('text.txt').read()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmOVKhk0YU7y",
        "outputId": "780bd12a-19e9-4a7e-ec2e-3c30e0a46796",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "translate(text)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O pt ing S or al S et al i as A le ad es A le ad es H os pl ac es H os al S et al es H as al re',\n",
              " 'Тип 1 ошибка в по ведении поведения в проведении уст ных исследований ( вероятности , что есть эффект , когда нет последствий ) часто устанавливаются на 0 , 1 % 0 , 1 % от',\n",
              " 'В последние годы исследова тели стали все чаще осозна вать исследования , которые наду вают уровень типа 1 ошибки .',\n",
              " 'Это означает , что исти нная ошибка типа 1 ошибка в случае превы шения или наду ва тельства выше номина льной ошибки 1 , set исследова телем .',\n",
              " 'Сим мон с , Не ль сон и Сим со сон ( 2011 ) описы вает ряд исследований , которые приводят к ситуации , когда исследова тели могут сказать , что существуют , и другие',\n",
              " 'По сути , все эти виды практики должны делать с множе ственными сопоста влений – в несколько раз , или выступать в качестве одного и того же гипоте за .',\n",
              " '« От вер ки » А . А . А . А . А . А . А . А . А . А . А . А . А . А . А .',\n",
              " 'Здесь мы сосредото чим на одном пути , в котором множество сопоста влений раз грузки типа 1 , извест ная как факульта тивный режим .',\n",
              " 'В факульта тивном отношении исследова теля неоднократно рассматри вался данные данные , продолжают сбор данных , когда испытание проводится не статисти чески значи мое , но останавли вает , когда в процессе проверки , когда',\n",
              " 'Мы научи мся , почему факульта тивно останавли ваться , но что вы должны сделать это правильно , управля я типа 1 ошибки .',\n",
              " 'Сначала посмотрим , как вели себя вели кими цен ностями , как вы собира ете данные .',\n",
              " 'Откры ть « По стро чный « Зна чение За вер с » ( O ver Time ) ».',\n",
              " 'R sc he , and run it . A . N as i as A le ad es H os pl es H os h al es H os pl es H app y H',\n",
              " 'Этот сценарий будет сим пи ровать в настоящее время коллек цию данных .',\n",
              " 'После 10 участников в каждом состоянии расчет ный вес рассчиты вается , при условии , что проведение независимого испытания и это те стов после повтор ного периода после повтор ного испытания .',\n",
              " 'Тогда все эти цен ны за говор чи ваются как функцию увеличения размера выбор ки .',\n",
              " 'Например , в Ри су ниже вы видите план за говор о ди - о сь ( от 0 до 1 ) и образец ( из 1 ) и образец ( для расчета )',\n",
              " 'Для этого модели рования , исти нного размера ( , указанного в стро ке 3 сцена рия ) является 0 , означает , что нет исти нного эффекта .',\n",
              " 'Таким образом , мы можем лишь соблюдать исти нные нега торы или лож ные положи тельные .',\n",
              " 'Мы будем говорить больше о разме рах в видео 4 . 1 , 4 . 2 и 4 . 3 . 3 . 4 . 3 . От ношения с кана лом Ad o be',\n",
              " 'Сейчас , просто знаю , что эффект , который эффект выражает силу того , что вы ис следовать .',\n",
              " 'Поскольку образец размера выбор ки , рост цен на медленно двига ется и вниз ( помни , от лек ций 1 . 2 , что когда нет реальных последствий , то есть , и он',\n",
              " 'В приведен ной ниже приведен ной ниже се рой ( указыва ющих на p - значение 0 , 05 ) около 51 и 60 участников .',\n",
              " '« От вер ки » А . А . А . А . А . А . А . А . А . А . А . А . А . А . А .',\n",
              " 'Если вы только посмотрите на данные однажды ( когда все участники собира ют ) стоимость па - на 0 , 05 только 5 % от стоимости , то , что вы можете увидеть , как',\n",
              " 'Вы можете проверить , стоит ли сть на 0 , 05 в вашей модели ровании , при которой внимание на графи ке , но сценарий также возвра щает самый низкий уровень .',\n",
              " 'Q 1 :',\n",
              " 'Раз работа йте сценарий 20 раз , и счита йте , как часто самое низ кое значение заканчивается ниже 0 . 05 ( мы рас считать долго й уровень вероятности , что будет иметь возможность',\n",
              " 'Если есть исти нное влияние , мы можем только соблюдать исти нную пози тивную или лож ную отрица тельную .',\n",
              " 'Изменение размера линии 3 от D < - 0 , 0 до D < - 0 . 3 .',\n",
              " 'Это срав нительно малые последствия , и с 200 участниками каждого состояния , у нас есть 85 % власти ( или 85 % вероятности поиска a , что может быть обнару жено .',\n",
              " 'R ay the sc or es .',\n",
              " 'Ниже приводится один пример тра ек то ри ческих цен , как увеличение размера выбор ки .',\n",
              " 'Q 2 :',\n",
              " 'R et the sc he av en ( 20 раз .',\n",
              " 'При смотри тесь на колеба ниях в тра ек тории под пи ри тель .',\n",
              " '« От вер ки » А . А . А . А . А . А . А . А . А . А . А . А . А . А . А .',\n",
              " 'Помните , что в N = 200 , 85 % раз в ча се « А ля ре » А . А . А . А . А . А . А . А .',\n",
              " 'p - значение должны закончи ться ниже 0 . 05 . 05 .',\n",
              " 'С цена , возвра щает образец размера размера от цен на ( который часто , но не всегда , в максимальной степени , в максимальной степени выбор ке , когда есть время , когда в',\n",
              " '- стоимость ка пель ниже 0 . 05 впервые .',\n",
              " 'Какое заявление правда ?',\n",
              " '« От вер ки » А . А . А . А . А . А . А . А . А . А . А . А . А . А . А .',\n",
              " 'A )',\n",
              " 'Если под пад ка ниже 0 . 05 , то он остается ниже 0 . 05 . 05 .',\n",
              " 'B )',\n",
              " 'От 0 и 1 , и каждый сейчас , и до конца до 0 . 05 .',\n",
              " 'C )',\n",
              " 'p - значение часто броса ются ниже 0 . 05 well до 200 участников в каждом состоянии .',\n",
              " 'В течение 50 % си мов , это уже происходит на N = 100 .',\n",
              " 'D )',\n",
              " 'Зна чение , как правило , пере дви нется ниже 0 . 05 и оста вайтесь там на некоторое время , но учитывая достаточно большой выбор , то он всегда пере дви жет назад .',\n",
              " 'Q 3 : изменить размер действия в соответствии с положениями 3 - D < - 0 , 8 , который может быть рассматриваться как большой эффект .',\n",
              " 'R et the sc he av en ( 20 раз .',\n",
              " 'При смотри тесь на колеба ниях в тра ек тории под пи ри тель .',\n",
              " 'Какое заявление правда ?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjI3Fc4AaXzr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-EdIyiPkKHS"
      },
      "source": [
        "text = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwm-yJJFjMXi"
      },
      "source": [
        "doc = model_en(text)\n",
        "translated_sent = []\n",
        "for sent in doc.sents:\n",
        "  sent = str(sent)\n",
        "  translated_sent.append(translate(sent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NVhJ_ZDkfQV"
      },
      "source": [
        "translated_sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25kX--upkipv",
        "outputId": "6cbea564-bb70-48fe-e552-3b17f8842b77"
      },
      "source": [
        "for sent in translated_sent:\n",
        "  print(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Факультативный протокол к\n",
            "Тип 1 ошибка в по ведении поведения в проведении уст ных исследований ( вероятности , что есть эффект , когда нет последствий ) часто устанавливаются на 0 , 1 % 0 , 1 % от\n",
            "В последние годы исследова тели стали все чаще осозна вать исследования , которые раз ду вают уровень типа 1 ошибки .\n",
            "Это означает , что исти нная ставка 1 ошибка в случае ошибки 1 выше , или за грузка , приведен ная в номина льной версии 1 , который был исследова телем .\n",
            "Сим мон с , Не ль сон и Сим со сон ( 2011 ) описы вает ряд исследований , которые приводят к ситуации , когда исследова тели могут сказать , что существуют , и другие\n",
            "По сути , все эти виды практики должны делать с множе ственными сопоста влений – в несколько раз , или выступать в качестве одного и того же гипоте за .\n",
            "-\n",
            "Здесь мы сосредото чим на одном пути , в котором множе ственные сопоста вления используются различные срав нение типа 1 .\n",
            "В факульта тивном отношении исследова теля неоднократно рассматри вался данные данные , продолжают сбор данных , когда испытание проводится не статисти чески значи мое , но останавли вает , когда в процессе проверки , когда\n",
            "Мы научи мся , почему факульта тивно останавли ваться , но что вы должны сделать это правильно , путем контроля за использованием типа 1 ошибки .\n",
            "Сначала посмотрим , как вели себя вели че ственные ценности , как вы собира ете данные .\n",
            "Откры ть о S ing le P os ition O ver Time .\n",
            "С цена и убе ри его .\n",
            "Этот сценарий будет сим мет ить в настоящее время коллек цию данных .\n",
            "После 10 участников в каждом состоянии расчет ный вес рассчиты вается , при условии , что проведение независимого испытания и это те стов после повтор ного периода после повтор ного испытания .\n",
            "Тогда все эти ценности зада ются в качестве функции увеличения размера выбор ки .\n",
            "Например , в Ри су ниже вы видите план за говор о ди - о сь ( от 0 до 1 ) и образец ( из 1 ) и образец ( для расчета )\n",
            "Для этого модели рования , исти нного размера ( указанные в стро ке 3 сцена рия ) это 0 , означает , что нет исти нного эффекта .\n",
            "Таким образом мы можем наблюдать только исти нные нега торы или лож ные пози ты .\n",
            "Мы будем говорить больше о разме рах в видео 4 . 1 , 4 . 2 , и 4 . 3 .\n",
            "Сейчас , просто знаю , что последствия , которые вы ис следу ете .\n",
            "Поскольку образец размера выбор ки , рост цен на медленно двига ется и вниз ( помни , от лек ций 1 . 2 , что когда нет реальных последствий , то есть , и он\n",
            "В приведен ной ниже приведен ной ниже се рой ( указыва ющих на p - значение 0 , 05 ) около 51 и 60 участников .\n",
            "-\n",
            "Если вы только посмотрите на данные однажды ( когда все участники собира ют ) стоимость па - на 0 , 05 только 5 % от стоимости , то , что вы можете увидеть , как\n",
            "Вы можете проверить , стоит ли сть на 0 , 05 в вашей модели ровании , при которой внимание на графи ке , но сценарий также возвра щает самый низкий уровень .\n",
            "1 :\n",
            "Раз работа йте сценарий 20 раз , и счита йте , как часто самое низ кое значение заканчивается ниже 0 . 05 ( мы рас считать долго й уровень вероятности , что будет иметь возможность\n",
            "Если есть исти нное влияние , мы можем лишь соблюдать исти нную пози тивную или лож ную отрица тельную .\n",
            "Изменение размера линии 3 от D < - 0 , 0 до D < - 0 . 3 .\n",
            "Это срав нительно малые последствия , и с 200 участниками каждого состояния , у нас есть 85 % власти ( или 85 % вероятности поиска a , что может быть обнару жено .\n",
            "Д a йте сценарий .\n",
            "Ниже приводится один пример тра ек тория цен ций , как увеличение размера выбор ки .\n",
            "Q 2 :\n",
            "Раз бе йте сценарий 20 раз .\n",
            "Взгляни на изменения в тра ек тории p - цен ят .\n",
            "-\n",
            "Помните , что в Н = 200 , 85 % раз в\n",
            "p - значение должны быть выполнены ниже 0 , 05 .\n",
            "С цена , возвра щает образец размера размера от цен на ( который часто , но не всегда , в максимальной степени , в максимальной степени выбор ке , когда есть время , когда в\n",
            "- стоимость ка пель ниже 0 , 05 для первого раза .\n",
            "Какое заявление правда ?\n",
            "-\n",
            "A )\n",
            "Если цена под пад ёт ниже 0 , 05 , то он остается ниже 0 . 05 .\n",
            "B )\n",
            "От стой но чные движения между 0 и 1 , и каждый сейчас все закончится ниже 0 , 05 .\n",
            "C )\n",
            "В каждой ситуации эта сумма часто броса ется ниже 0 , 05 well до 200 участников .\n",
            "В течение 50 % си мов , это уже происходит в N = 100 .\n",
            "D )\n",
            "Зна чение , как правило , пере дви нется ниже 0 . 05 и оста вайтесь там на некоторое время , но учитывая достаточно большой выбор , то он всегда пере дви жет назад .\n",
            "Q 3 : изменить размер эффекта , размер которого составляет 3 до D < - 0 , 8 , который может быть рассматриваться в качестве большого эффекта .\n",
            "Раз бе йте сценарий 20 раз .\n",
            "Взгляни на изменения в тра ек тории p - цен ят .\n",
            "Какое заявление правда ?\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}